{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from utils import load_data, split_data\n",
    "import os\n",
    "\n",
    "print(f\"tensorflow: {tf.__version__}\")\n",
    "print(f\"keras: {tf.keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DATA_DIR ../data/GSE92742_Broad_LINCS\n",
    "\n",
    "data_dir = os.environ['DATA_DIR']\n",
    "\n",
    "data_fname = 'GSE92742_Broad_LINCS_Level4_ZSPCINF_mlr12k_n1319138x12328.gctx'\n",
    "data_path = os.path.join(data_dir, data_fname)\n",
    "\n",
    "sample_meta_fname = 'GSE92742_Broad_LINCS_inst_info.txt'\n",
    "sample_meta_path = os.path.join(data_dir, sample_meta_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw data, selecting for cells by treatment\n",
    "pert_types = [\n",
    "    'trt_cp',       # treated with compound\n",
    "    'ctl_vehicle',  # control for compound treatment (e.g DMSO) \n",
    "    'ctl_untrt'     # untreated samples\n",
    "]\n",
    "\n",
    "cell_ids = [\n",
    "    'MCF7', \n",
    "    'PC3', \n",
    "    'HA1E', \n",
    "    'HCC515'\n",
    "]\n",
    "\n",
    "sample_meta, gene_labels, data = load_data(data_path, sample_meta_path, pert_types, cell_ids)\n",
    "print(f\"data size: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation, and testing\n",
    "train, val, test = split_data(data, sample_labs, 0.2)\n",
    "print(f\"training size: {train[0].shape[0]}\")\n",
    "print(f\"validation size: {val[0].shape[0]}\")\n",
    "print(f\"testing size: {test[0].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "\n",
    "def create_AE(hidden_layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "    for nunits in hidden_layers:\n",
    "        model.add(layers.Dense(nunits, activation='relu'))\n",
    "        \n",
    "    model.add(layers.Dense(978, activation='linear'))\n",
    "    return model\n",
    "\n",
    "def create_dataset(X, y, shuffle_buffer_size=10_000, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X,y))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    dataset = dataset.batch(batch_size=32)\n",
    "    # `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= create_dataset(train[0], train[0], train[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_AE([120, 32, 120])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
