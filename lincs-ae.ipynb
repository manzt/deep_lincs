{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.0.0-beta1\n",
      "keras: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(f\"tensorflow: {tf.__version__}\")\n",
    "print(f\"keras: {tf.keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/GSE92742_Broad_LINCS\"\n",
    "out_dir = \"data/output\"\n",
    "\n",
    "fnames = [\n",
    "    \"Level3_INF_mlr12k_n1319138x12328.gctx\",\n",
    "    \"gene_info_delta_landmark.txt\",\n",
    "    \"inst_info.txt\",\n",
    "    \"pert_info.txt\",\n",
    "    \"cell_info.txt\",\n",
    "]\n",
    "\n",
    "fpaths = {\n",
    "    \"_\".join(f.split(\".\")[0].split('_')[:2]): f\"{data_dir}/{f}\" for f in fnames\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load data and extract untreated samples for DE analysis\n",
    "#### Load data\n",
    "Extract all samples for training model (VCAP, MCF7, PC3), but filter for untreated and save for DE analysis in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LINCS Dataset: (samples: 333,523, genes: 978)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.utils import load_data\n",
    "\n",
    "pert_types = [\n",
    "    \"trt_cp\",  # treated with compound\n",
    "    \"ctl_vehicle\",  # control for compound treatment (e.g DMSO)\n",
    "    \"ctl_untrt\",  # untreated samples\n",
    "]\n",
    "\n",
    "cell_ids = [\"VCAP\", \"MCF7\", \"PC3\"]  # prostate tumor  # breast tumor  # prostate tumor\n",
    "\n",
    "# Load Data\n",
    "dset = load_data(\n",
    "    fpaths[\"Level3_INF\"], fpaths[\"inst_info\"], fpaths[\"gene_info\"], pert_types, cell_ids\n",
    ")\n",
    "\n",
    "dset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample controls and save to disk \n",
    "Extract the control samples for DE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_data = dset.filter_rows(pert_type=[\"ctl_vehicle\", \"ctl_untrt\"])\n",
    "ctrl_data.sample_rows(meta_groups=\"cell_id\", size=100).to_tsv(out_dir, name='control')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size:   <LINCS Dataset: (samples: 213,454, genes: 978)>\n",
      "validation size: <LINCS Dataset: (samples: 53,364, genes: 978)>\n",
      "testing size:    <LINCS Dataset: (samples: 66,705, genes: 978)>\n"
     ]
    }
   ],
   "source": [
    "from lib.models import create_AE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "dset.normalize_by_gene()\n",
    "dset.train_val_test_split()\n",
    "\n",
    "print(f\"training size:   {dset.train}\")\n",
    "print(f\"validation size: {dset.val}\")\n",
    "print(f\"testing size:    {dset.test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               125312    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 978)               126162    \n",
      "=================================================================\n",
      "Total params: 252,116\n",
      "Trainable params: 252,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "h_size = 2\n",
    "model = create_AE([128, h_size, 128])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0704 14:56:00.799813 140053905606464 deprecation.py:323] From /Users/manz01/miniconda3/envs/lincs-gpu/lib/python3.6/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f609228a1d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model.fit(\n",
    "    dset.train.to_tf_dataset(target=\"self\", batch_size=batch_size),\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    steps_per_epoch=dset.train.data.shape[0] // batch_size,\n",
    "    validation_data=(dset.val.data.values, dset.val.data.values),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66705/66705 [==============================] - 3s 38us/sample - loss: 0.0215 - cosine_similarity: 0.9695 - pearsons_corrcoef: 0.6653\n",
      "loss: [0.02149388829262778, 0.9694666, 0.66528803]\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(dset.test.data.values, dset.test.data.values)\n",
    "print(f\"loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine hidden output for control samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_0</th>\n",
       "      <th>unit_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inst_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KDB002_MCF7_96H_X3_B1_DUO53HI52LO:F16</th>\n",
       "      <td>3.161170</td>\n",
       "      <td>2.821518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOS032_MCF7_24H_X1_F2B4_DUO52HI53LO:F10</th>\n",
       "      <td>2.853788</td>\n",
       "      <td>4.297601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERGK006_VCAP_120H_X3_B2_DUO52HI53LO:G20</th>\n",
       "      <td>0.766446</td>\n",
       "      <td>4.115182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPD002_MCF7_6H_X3_B6_DUO52HI53LO:F05</th>\n",
       "      <td>2.517581</td>\n",
       "      <td>4.088450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDA009_MCF7_96H_X2_B1_DUO45HI44LO:N13</th>\n",
       "      <td>4.230115</td>\n",
       "      <td>4.262281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unit_0    unit_1\n",
       "inst_id                                                    \n",
       "KDB002_MCF7_96H_X3_B1_DUO53HI52LO:F16    3.161170  2.821518\n",
       "DOS032_MCF7_24H_X1_F2B4_DUO52HI53LO:F10  2.853788  4.297601\n",
       "ERGK006_VCAP_120H_X3_B2_DUO52HI53LO:G20  0.766446  4.115182\n",
       "CPD002_MCF7_6H_X3_B6_DUO52HI53LO:F05     2.517581  4.088450\n",
       "KDA009_MCF7_96H_X2_B1_DUO45HI44LO:N13    4.230115  4.262281"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.utils import get_hidden_activations\n",
    "# Extract control samples from testing data\n",
    "test_ctrl_data = dset.test.filter_rows(pert_type=[\"ctl_vehicle\", \"ctl_untrt\"])\n",
    "\n",
    "encoder = tf.keras.Model(inputs=model.layers[0].input, outputs=model.layers[1].output)\n",
    "hidden_output = get_hidden_activations(test_ctrl_data.data, encoder)\n",
    "hidden_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find 100 the most activating in each unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import get_most_activating_ids\n",
    "\n",
    "# Find the most activating samples for each unit\n",
    "most_activating_ids = get_most_activating_ids(hidden_output, size=100)\n",
    "\n",
    "# Lookup the most activating samples by id\n",
    "most_activating_samples = {\n",
    "    unit: dset.lookup_samples(ids).data for unit, ids in most_activating_ids.items()\n",
    "}\n",
    "\n",
    "# Write most activating samples to disk for DE analysis\n",
    "for unit, df in most_activating_samples.items():\n",
    "    df.to_csv(f\"data/activating_units/{unit}_most_activating.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.zero_out import zero_out_method\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroed_rank = zero_out_method(encoder, test_ctrl_data)\n",
    "zeroed_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_freq = (\n",
    "    zeroed_rank.join(dset.sample_meta)  # add metadata for each sample\n",
    "    .groupby([\"cell_id\", \"unit\", \"gene_id\"])\n",
    "    .size()  # count the frequency of each gene_id for each unit for each cell id\n",
    "    .reset_index(name=\"freq\")\n",
    ")\n",
    "count_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_count_freq = pd.merge(\n",
    "    count_freq,\n",
    "    pd.read_csv(fpaths[\"gene_info\"], sep=\"\\t\"),\n",
    "    left_on=\"gene_id\",\n",
    "    right_on=\"pr_gene_id\",\n",
    ")\n",
    "\n",
    "# ctrl scatter baseplot\n",
    "base = alt.Chart(hidden_output.join(dset.test.sample_meta).reset_index())\n",
    "\n",
    "# selections\n",
    "selection = alt.selection_single(fields=[\"cell_id\"])\n",
    "pts = alt.selection_multi(fields=[\"pert_id\"])\n",
    "\n",
    "scatter = (\n",
    "    base\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X(\"unit_0:Q\", bin=alt.Bin(maxbins=20)),\n",
    "        y=\"count()\",\n",
    "        color=alt.condition(pts, alt.Color(\"cell_id:N\"), alt.value(\"lightgray\")),\n",
    "        tooltip=[\"cell_id:N\", \"pert_id:N\", \"pert_iname:N\", \"pert_type:N\"],\n",
    "    )\n",
    "    .properties(height=200, width=600)\n",
    "    .add_selection(selection)\n",
    ")\n",
    "\n",
    "pert_info_bar = (\n",
    "    base.mark_bar()\n",
    "    .encode(\n",
    "        x=\"count()\",\n",
    "        y=alt.Y(\n",
    "            \"pert_id:N\",\n",
    "            sort=alt.EncodingSortField(field=\"pert_id\", op=\"count\", order=\"descending\"),\n",
    "            axis=alt.Axis(orient=alt.AxisOrient(\"right\"))\n",
    "        ),\n",
    "        color=alt.condition(pts, alt.ColorValue(\"grey\"), alt.ColorValue(\"lightgrey\")),\n",
    "    )\n",
    "    .properties(height=100, width=600)\n",
    "    .add_selection(pts)\n",
    ")\n",
    "\n",
    "barplot = (\n",
    "    alt.Chart(gene_count_freq)\n",
    "    .transform_filter(selection)\n",
    "    .transform_filter(alt.datum.freq > 10)\n",
    "    .transform_calculate(url=\"https://www.ncbi.nlm.nih.gov/gene/\" + alt.datum.gene_id)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"pr_gene_symbol:N\",\n",
    "            sort=alt.EncodingSortField(field=\"freq\", order=\"descending\"),\n",
    "        ),\n",
    "        y=\"freq:Q\",\n",
    "        color=\"cell_id:N\",\n",
    "        href=\"url:N\",\n",
    "        tooltip=[\"gene_id:N\", \"pr_gene_symbol:N\", \"freq:Q\"],\n",
    "    )\n",
    "    .properties(height=100, width=850)\n",
    "    .facet(row=\"unit\")\n",
    ")\n",
    "\n",
    "barplot & (scatter & pert_info_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
